---
title: 白板机器学习总结
tags: 频率派,贝叶斯派
renderNumberedHeading: true
grammar_cjkRuby: true
grammar_mathjax: true
---
# 简介
`对概率的诠释有两大学派，一种是频率派另一种是贝叶斯派`

`!$ {X_{N \times p}} = {({x_1},{x_2},...,{x_N})^T},xi = {({x_{i1}},{x_{i2}},...,{x_{ip}})^T}$`
这个记号表示有  个样本，每个样本都是  维向量。其中每个观测都是由 `!$p(x|\theta )$` 生成的。
## 频率派
假设参数θ是常量。对于N个观测来说，观测集的概率为`!$p(x|\theta )\mathop  = \limits_{iid} \prod\limits_{i = 1}^N {p({x_i}|\theta )} $`。为了求θ大小，我们采用最大对数似然估计MLE的方法：
```mathjax!
\[{\theta _{MLE}} = \mathop {\arg \max }\limits_\theta  \log p(X|\theta )\mathop  = \limits_{iid} \mathop {\arg \max }\limits_\theta  \sum\limits_{i = 1}^N {\log p({x_i}|\theta )} \]
```
## 贝叶斯派
贝叶斯派则认为参数 θ 不是一个常量，**而是一个满足预设的先验分步的变量，即 `!$\theta \sim p(\theta )$`**。于是根据贝叶斯定理依赖观测集参数的后验可以写成：
```mathjax!

```
